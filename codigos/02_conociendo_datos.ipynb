{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb3248a",
   "metadata": {},
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ff8fd",
   "metadata": {},
   "source": [
    "Rutas de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa9ed349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR resolved to: c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\n",
      "INPUT_CSV exists?: True\n"
     ]
    }
   ],
   "source": [
    "# Robust data directory resolution for both script and notebook\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def locate_data_processed(filename='datos_sima_limpios_combined.csv'):\n",
    "    # Try to use __file__ when available (script execution)\n",
    "    try:\n",
    "        start = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        start = Path.cwd()\n",
    "\n",
    "    # Try a sequence of candidate starting points and their parents\n",
    "    candidates = [start, Path.cwd(), start.parent, Path.cwd().parent]\n",
    "    # Also include a few ancestor levels for each candidate\n",
    "    for c in candidates:\n",
    "        if c is None:\n",
    "            continue\n",
    "        for p in [c] + list(c.parents)[:5]:\n",
    "            dp = p / 'data_processed'\n",
    "            if dp.exists() and (dp / filename).exists():\n",
    "                return dp\n",
    "\n",
    "    # If no folder contains the file, prefer any existing data_processed folder\n",
    "    for c in candidates:\n",
    "        dp = Path(c) / 'data_processed'\n",
    "        if dp.exists():\n",
    "            return dp\n",
    "\n",
    "    # Last resort: assume a data_processed at start\n",
    "    return Path(start) / 'data_processed'\n",
    "\n",
    "DATA_DIR = locate_data_processed()\n",
    "INPUT_CSV = DATA_DIR / 'datos_sima_limpios_combined.csv'\n",
    "OUT_AGG = DATA_DIR / 'datos_aggregados_dia_estacion_franja.csv'\n",
    "\n",
    "print('DATA_DIR resolved to:', DATA_DIR)\n",
    "print('INPUT_CSV exists?:', INPUT_CSV.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6309a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a normalized calendar CSV so main() can save it\n",
    "import pandas as pd\n",
    "\n",
    "def format_calendar_for_csv(calendario, out_path):\n",
    "    \"\"\"Escribe un CSV con columnas: estacion, start, end (formato 'YYYY-MM-DD HH:MM:SS').\n",
    "    Devuelve la ruta escrita como string.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for est, intervals in calendario.items():\n",
    "        for s, e in intervals:\n",
    "            rows.append({'estacion': est, 'start': s, 'end': e})\n",
    "    df_cal = pd.DataFrame(rows)\n",
    "    out = Path(out_path)\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_cal.to_csv(out, index=False)\n",
    "    return str(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20a827",
   "metadata": {},
   "source": [
    "Calendario por estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02b93fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALENDARIO_POR_ESTACION = {\n",
    "    'CENTRO': [\n",
    "        ('2023-01-09 00:00:00', '2023-05-12 00:00:00'),\n",
    "        ('2023-08-07 00:00:00', '2023-12-01 00:00:00'),\n",
    "        ('2024-01-15 00:00:00', '2024-05-10 00:00:00'),\n",
    "        ('2024-08-05 00:00:00', '2024-11-29 00:00:00'),\n",
    "        ('2025-01-06 00:00:00', '2025-05-09 00:00:00')\n",
    "    ],\n",
    "    'SUROESTE2': [\n",
    "        ('2023-01-09 00:00:00', '2023-05-12 00:00:00'),\n",
    "        ('2023-08-07 00:00:00', '2023-12-06 00:00:00'),\n",
    "        ('2024-01-10 00:00:00', '2024-05-24 00:00:00'),\n",
    "        ('2024-08-05 00:00:00', '2024-12-05 00:00:00'),\n",
    "        ('2025-01-13 00:00:00', '2025-05-23 00:00:00')\n",
    "    ],\n",
    "    'SUR': [\n",
    "        ('2023-01-23 00:00:00', '2023-06-30 00:00:00'),\n",
    "        ('2023-08-07 00:00:00', '2023-12-06 00:00:00'),\n",
    "        ('2024-01-22 00:00:00', '2024-06-28 00:00:00'),\n",
    "        ('2024-08-05 00:00:00', '2024-12-05 00:00:00'),\n",
    "        ('2025-01-20 00:00:00', '2025-06-27 00:00:00')\n",
    "    ],\n",
    "    'NORTE2': [\n",
    "        ('2023-01-09 00:00:00', '2023-07-01 00:00:00'),\n",
    "        ('2023-08-23 00:00:00', '2023-12-15 00:00:00'),\n",
    "        ('2024-01-08 00:00:00', '2024-07-16 00:00:00'),\n",
    "        ('2024-08-26 00:00:00', '2024-12-18 00:00:00'),\n",
    "        ('2025-01-09 00:00:00', '2025-07-16 00:00:00')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adfead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=INPUT_CSV):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Archivo no encontrado: {path}. Ejecute la etapa 1 primero.\")\n",
    "    df = pd.read_csv(path, parse_dates=['date'], dayfirst=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3bae441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_vars(df):\n",
    "    df = df.copy()\n",
    "    if 'date' not in df.columns:\n",
    "        raise KeyError('La columna `date` no está presente.')\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df['anio'] = df['date'].dt.year\n",
    "    df['mes'] = df['date'].dt.month\n",
    "    df['dia'] = df['date'].dt.day\n",
    "    df['hora'] = df['date'].dt.hour\n",
    "\n",
    "    try:\n",
    "        df['dia_semana'] = df['date'].dt.day_name(locale='es_ES')\n",
    "    except Exception:\n",
    "        df['dia_semana'] = df['date'].dt.day_name()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ba5d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_franja(h):\n",
    "    # h: integer hour (0-23)\n",
    "    if h in [7, 8]:\n",
    "        return 'pico_7_9'\n",
    "    elif h in [10, 11]:\n",
    "        return 'ref_10_12'\n",
    "    else:\n",
    "        return 'fuera_franja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c3a625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clase_from_calendar(df, calendario=CALENDARIO_POR_ESTACION):\n",
    "    \"\"\"Asigna la variable `clase` (1/0) a partir de `calendario`.\n",
    "\n",
    "    El calendario debe ser un dict: estacion -> list of (start_str, end_str), fechas 'YYYY-MM-DD'.\n",
    "    Si una estación no está en el calendario, se asigna `clase=0` y se imprime advertencia.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['clase'] = 0\n",
    "    # Preprocesar calendario: convertir a datetimes\n",
    "    cal_proc = {}\n",
    "    for est, intervals in calendario.items():\n",
    "        parsed = []\n",
    "        for start_s, end_s in intervals:\n",
    "            try:\n",
    "                s = pd.to_datetime(start_s)\n",
    "                e = pd.to_datetime(end_s)\n",
    "                parsed.append((s, e))\n",
    "            except Exception:\n",
    "                continue\n",
    "        if parsed:\n",
    "            cal_proc[est] = parsed\n",
    "\n",
    "    missing_stations = set(df['estacion'].dropna().unique()) - set(cal_proc.keys())\n",
    "    if missing_stations:\n",
    "        print(f\"Advertencia: las siguientes estaciones no están en el calendario y recibirán clase=0: {sorted(list(missing_stations))}\")\n",
    "\n",
    "    def is_in_class(row):\n",
    "        est = row['estacion']\n",
    "        dt = row['date']\n",
    "        if pd.isna(est) or pd.isna(dt):\n",
    "            return 0\n",
    "        # If station not in calendar, it's outside class\n",
    "        if est not in cal_proc:\n",
    "            return 0\n",
    "        # Sólo lunes-viernes\n",
    "        if dt.weekday() >= 5:\n",
    "            return 0\n",
    "        for (s, e) in cal_proc[est]:\n",
    "            # comparar solo fecha (sin hora)\n",
    "            if s.normalize() <= dt.normalize() <= e.normalize():\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    df['clase'] = df.apply(is_in_class, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c648bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_aggregate(df):\n",
    "    \"\"\"Selecciona las horas objetivo (7,8,10,11), asigna `franja_horaria` y devuelve\n",
    "    filas con `date`, `anio`,`mes`,`dia`,`hora`,`estacion`,`franja_horaria`,`parametro`,`valor`,`clase`.\n",
    "\n",
    "    No se agregan medias/medianas/contajes — se preserva cada registro horario relevante.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Mantener sólo parámetros esperados\n",
    "    expected = ['NO2', 'CO', 'PM2.5', 'PM10', 'O3']\n",
    "    df = df[df['parametro'].isin(expected)]\n",
    "\n",
    "    # Filtrar a las horas exactas solicitadas\n",
    "    target_hours = [7, 8, 10, 11]\n",
    "    df = df[df['hora'].isin(target_hours)]\n",
    "\n",
    "    # Asignar franja según hora\n",
    "    df['franja_horaria'] = df['hora'].apply(assign_franja)\n",
    "\n",
    "    # Seleccionar y devolver columnas deseadas, preservando `valor` y `clase` si existe\n",
    "    cols = ['date','anio','mes','dia','hora','estacion','franja_horaria','parametro','valor','clase']\n",
    "    # Asegurar que las columnas existan en el df\n",
    "    existing = [c for c in cols if c in df.columns]\n",
    "    out = df[existing].copy()\n",
    "\n",
    "    # Orden consistente\n",
    "    final_cols = [c for c in cols if c in out.columns]\n",
    "    return out[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8c10451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_aggregated(agg_df, path=OUT_AGG):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    agg_df.to_csv(path, index=False)\n",
    "    print(f\"✓ Agregados guardados en: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcd18a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acf(series, nlags=30):\n",
    "    if acf is None:\n",
    "        raise ImportError('statsmodels no disponible. Instale statsmodels para usar ACF.')\n",
    "    series = series.dropna()\n",
    "    return acf(series, nlags=nlags, fft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bdf5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ljungbox(series, lags=[10]):\n",
    "    if acorr_ljungbox is None:\n",
    "        raise ImportError('statsmodels no disponible. Instale statsmodels para Ljung-Box.')\n",
    "    series = series.dropna()\n",
    "    res = acorr_ljungbox(series, lags=lags, return_df=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acfaf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_durbin_watson(residuals):\n",
    "    if durbin_watson is None:\n",
    "        raise ImportError('statsmodels no disponible. Instale statsmodels para Durbin-Watson.')\n",
    "    return durbin_watson(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('\\n== Parte 2: creación de variables y agregación ==')\n",
    "    print(f'Leyendo: {INPUT_CSV}')\n",
    "    df = load_data(INPUT_CSV)\n",
    "    print(f'Registros cargados: {len(df):,}')\n",
    "\n",
    "    df = create_time_vars(df)\n",
    "    print('Variables temporales creadas: anio, mes, dia, hora, dia_semana')\n",
    "\n",
    "    print('Asignando variable `clase` según calendario...')\n",
    "    if not CALENDARIO_POR_ESTACION:\n",
    "        print('  ATENCIÓN: `CALENDARIO_POR_ESTACION` está vacío. Edite el script y agregue los periodos por estación antes de ejecutar para obtener `clase=1` cuando corresponda.')\n",
    "    # Exportar versión normalizada del calendario con formato 'YYYY-MM-DD HH:MM:SS'\n",
    "    try:\n",
    "        # Usar DATA_DIR (siempre disponible en notebook y script)\n",
    "        cal_export_path = DATA_DIR / 'calendario_estaciones_normalized.csv'\n",
    "        norm_out = format_calendar_for_csv(CALENDARIO_POR_ESTACION, cal_export_path)\n",
    "        if norm_out:\n",
    "            print(f'  Calendario normalizado guardado en: {norm_out}')\n",
    "    except Exception as e:\n",
    "        print(f'  No fue posible exportar calendario normalizado: {e}')\n",
    "\n",
    "    df = assign_clase_from_calendar(df, calendario=CALENDARIO_POR_ESTACION)\n",
    "\n",
    "    print('Filtrando franjas y agregando por día-estación-franja...')\n",
    "    agg = filter_and_aggregate(df)\n",
    "    save_aggregated(agg)\n",
    "\n",
    "    print('\\nTareas siguientes sugeridas:')\n",
    "    print('- Rellenar `CALENDARIO_POR_ESTACION` con los intervalos reales por estación.')\n",
    "    print('- Ejecutar nuevamente para obtener `clase` correcta y luego aplicar pruebas ACF/Ljung-Box/Durbin-Watson con las funciones disponibles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4190b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Parte 2: creación de variables y agregación ==\n",
      "Leyendo: c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\\datos_sima_limpios_combined.csv\n",
      "Registros cargados: 1,804,203\n",
      "Registros cargados: 1,804,203\n",
      "Variables temporales creadas: anio, mes, dia, hora, dia_semana\n",
      "Asignando variable `clase` según calendario...\n",
      "  DEBUG: DATA_DIR=c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\n",
      "  DEBUG: format_calendar_for_csv defined? True\n",
      "  DEBUG: cal_export_path=c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\\calendario_estaciones_normalized.csv\n",
      "  Calendario normalizado guardado en: c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\\calendario_estaciones_normalized.csv\n",
      "Variables temporales creadas: anio, mes, dia, hora, dia_semana\n",
      "Asignando variable `clase` según calendario...\n",
      "  DEBUG: DATA_DIR=c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\n",
      "  DEBUG: format_calendar_for_csv defined? True\n",
      "  DEBUG: cal_export_path=c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\\calendario_estaciones_normalized.csv\n",
      "  Calendario normalizado guardado en: c:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\data_processed\\calendario_estaciones_normalized.csv\n",
      "Advertencia: las siguientes estaciones no están en el calendario y recibirán clase=0: ['NORESTE3', 'NOROESTE3']\n",
      "Advertencia: las siguientes estaciones no están en el calendario y recibirán clase=0: ['NORESTE3', 'NOROESTE3']\n",
      "Filtrando franjas y agregando por día-estación-franja...\n",
      "Filtrando franjas y agregando por día-estación-franja...\n",
      "✓ Agregados guardados en: C:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\codigos\\data_processed\\datos_aggregados_dia_estacion_franja.csv\n",
      "\n",
      "Tareas siguientes sugeridas:\n",
      "- Rellenar `CALENDARIO_POR_ESTACION` con los intervalos reales por estación.\n",
      "- Ejecutar nuevamente para obtener `clase` correcta y luego aplicar pruebas ACF/Ljung-Box/Durbin-Watson con las funciones disponibles.\n",
      "✓ Agregados guardados en: C:\\Users\\anala\\Documents\\Semestre 5\\Reto-multivariados-equipo-5\\codigos\\data_processed\\datos_aggregados_dia_estacion_franja.csv\n",
      "\n",
      "Tareas siguientes sugeridas:\n",
      "- Rellenar `CALENDARIO_POR_ESTACION` con los intervalos reales por estación.\n",
      "- Ejecutar nuevamente para obtener `clase` correcta y luego aplicar pruebas ACF/Ljung-Box/Durbin-Watson con las funciones disponibles.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV agregado y extraer componentes de fecha\n",
    "agg_df = pd.read_csv(OUT_AGG, parse_dates=['date'])\n",
    "\n",
    "# Ya tenemos anio, mes, dia en el CSV. Vamos a verificar y agregar hora si falta\n",
    "print(\"Primeras 5 filas del agregado:\")\n",
    "print(agg_df.head())\n",
    "print(f\"\\nColumnas disponibles:\\n{agg_df.columns.tolist()}\")\n",
    "print(f\"\\nForma del dataset: {agg_df.shape}\")\n",
    "\n",
    "# Extraer hora de la columna 'date' si no está ya\n",
    "if 'hora' not in agg_df.columns:\n",
    "    agg_df['hora'] = agg_df['date'].dt.hour\n",
    "    print(\"\\n✓ Columna 'hora' extraída de 'date'\")\n",
    "\n",
    "# Ver distribuición de datos\n",
    "print(\"\\n== Resumen ==\")\n",
    "print(f\"Estaciones: {agg_df['estacion'].unique()}\")\n",
    "print(f\"Parámetros: {agg_df['parametro'].unique()}\")\n",
    "print(f\"Franjas: {agg_df['franja_horaria'].unique()}\")\n",
    "print(f\"Años: {sorted(agg_df['anio'].unique())}\")\n",
    "print(f\"Rango de fechas: {agg_df['date'].min()} a {agg_df['date'].max()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
